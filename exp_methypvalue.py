# -*- coding: utf-8 -*-
"""exp_methyPvalue.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IPIrXD9XqP7g-pG9s03RgiU2uNZJphGm
"""

import pandas as pd
import numpy as np

import numpy as np
import torch
from torch import nn
from sklearn.metrics import accuracy_score
import math
#import matplotlib.pyplot as plt
import sys
import pandas as pd
from torch import linalg as LA
import torch.utils.data
from torch.utils.data.dataset import Dataset
import copy
import torchvision.transforms as transforms
from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data.sampler import SequentialSampler
import random
from math import floor
import torch.nn.functional as F
from torch.nn import init
from sklearn.metrics import roc_auc_score
from functools import reduce
from sklearn.metrics import accuracy_score
np.seterr(divide='ignore', invalid='ignore')

from sklearn.metrics import roc_auc_score,accuracy_score
from sklearn.model_selection import train_test_split
from scipy.stats import ttest_ind
from sklearn import svm

from functools import reduce
from sklearn.metrics import f1_score
from sklearn.ensemble import RandomForestClassifier
import argparse

aml_exp = pd.read_csv("/content/sample_data/exp1.csv")
#size = np.size(aml_exp_size,0)
#size
aml_exp

mRNA_train_data=torch.from_numpy(aml_exp)
mRNA_train_data

aml_methy = pd.read_csv("/content/mRNA.csv",index_col=0)
#np.size(aml_methy,0)
df = aml_methy
numpy_array = df.to_numpy()
data = numpy_array.astype(np.float64)
size = np.size(aml_methy_size,0)
#size

from google.colab import drive
drive.mount('/content/drive')

mRNA_train_data=torch.from_numpy(data)
mRNA_train_data

mRNA = np.array(aml_methy).transpose().astype(np.float32)
mRNA_train_data=torch.from_numpy(mRNA)
mRNA_train_data

sample_size = 20531
mRNA_train_labels = torch.zeros(sample_size)

mRNA_train_set = [(mRNA_train_data[i], mRNA_train_labels[i]) for i in range(sample_size)]
mRNA_train_set









aml_exp = pd.read_csv("/content/sample_data/expT.csv")
#df1 = aml_exp.T
df1 = aml_exp
df1

df1 = df1.drop(columns="sample")

exp_columnsName = df1.columns
exp_columnsName

aml_methy = pd.read_csv("/content/sample_data/methyT.csv")
#df2 = aml_methy.T
df2 = aml_methy
df2

df2 = df2.drop(columns="sample")

methy_columnsName = df2.columns
methy_columnsName

"""# correlation"""

pd.set_option('display.max_columns', None)
correlationData = pd.concat([df1, df2], axis=1, keys=['df1', 'df2']).corr().loc['df1', 'df2']
correlationData

df = pd.DataFrame(correlationData)
df

correlationABS = correlationData.abs()
correlationABS

correlationABS = correlationData.abs()
print(correlationABS.max(numeric_only=True).max())

#median
medianVal = correlationABS.stack().median()
median= "{:.2f}".format(medianVal)
median

valueS = correlationABS.values
valueS

# Get all names 
for col_name in correlationABS.columns: 
    print(col_name)

#rows name
for row_name in correlationABS.index: 
    print(row_name)

df = pd.DataFrame(correlationABS)
df



"""median 0.05"""

#syntax: df[“column_name”] = np.where(df[“column_name”]==”some_value”, value_if_true, value_if_false)
for col_name in correlationABS.columns: 
    for row_name in correlationABS.index:
        correlationABS[col_name][row_name] = np.where(correlationABS[col_name][row_name] >= 0.05, 1,0)
correlationABS

correlationABS.to_csv("pValueData.csv")

